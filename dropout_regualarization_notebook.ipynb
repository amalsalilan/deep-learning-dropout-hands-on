{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cb2b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef1653e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('sonar_dataset.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9605d9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a1c50e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGbCAYAAADuu2vDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAXkElEQVR4nO3dfWyddfn48etsjLJhV9iQloYOSmwiOlQcZHGgm8KKc0PNoqAbiIBmpDxYpk6WKRQSWpk6G2mcGQIbkjn+AYWouPo0JJMwBvgwCMQwRwWaRi1tgdnBdn5/kJ3ft4wH0VPO1e31Su6E+3M+Pb2acNh7d+/DKRSLxWIAACQyrtIDAAC8kkABANIRKABAOgIFAEhHoAAA6QgUACAdgQIApCNQAIB0Dqr0AP+NPXv2xNNPPx3V1dVRKBQqPQ4A8B8oFosxNDQU9fX1MW7c618jGZOB8vTTT0dDQ0OlxwAA/gs9PT1x9NFHv+6eMRko1dXVEfHyDzh58uQKTwMA/CcGBwejoaGh9Of46xmTgbL31zqTJ08WKAAwxvwnt2e4SRYASEegAADpCBQAIB2BAgCkI1AAgHQECgCQjkABANIRKABAOgIFAEhHoAAA6QgUACAdgQIApCNQAIB0BAoAkM5BlR6AN+fYK35W6RF4C/3tm/MrPQJARbiCAgCkI1AAgHQECgCQjkABANIRKABAOgIFAEhHoAAA6QgUACAdgQIApCNQAIB0BAoAkI5AAQDSESgAQDoCBQBIR6AAAOkIFAAgHYECAKQjUACAdAQKAJCOQAEA0hEoAEA6AgUASEegAADpCBQAIB2BAgCkI1AAgHQECgCQjkABANIRKABAOgIFAEjnTQfKPffcE2eeeWbU19dHoVCIn/zkJyMeLxaL0dbWFvX19TFx4sSYM2dObNu2bcSe4eHhuPTSS+OII46IQw89ND7+8Y/H3//+9//pBwEA9h9vOlCef/75eO973xtdXV2v+vjKlStj1apV0dXVFVu2bIm6urqYO3duDA0Nlfa0trbGHXfcERs2bIh77703nnvuuViwYEHs3r37v/9JAID9xkFv9gvmzZsX8+bNe9XHisVidHZ2xooVK2LhwoUREbFu3bqora2N9evXx5IlS2JgYCBuvPHG+NGPfhSnn356RETceuut0dDQEL/61a/ijDPO+B9+HABgf1DWe1C2b98evb290dzcXFqrqqqK2bNnx+bNmyMiYuvWrfHiiy+O2FNfXx/Tp08v7Xml4eHhGBwcHHEAAPuvsgZKb29vRETU1taOWK+trS091tvbGwcffHAcfvjhr7nnlTo6OqKmpqZ0NDQ0lHNsACCZUXkXT6FQGHFeLBb3WXul19uzfPnyGBgYKB09PT1lmxUAyKesgVJXVxcRsc+VkL6+vtJVlbq6uti1a1f09/e/5p5XqqqqismTJ484AID9V1kDpbGxMerq6qK7u7u0tmvXrti0aVPMmjUrIiJmzJgREyZMGLHnmWeeib/85S+lPQDAge1Nv4vnueeei7/+9a+l8+3bt8fDDz8cU6ZMiWnTpkVra2u0t7dHU1NTNDU1RXt7e0yaNCkWLVoUERE1NTVx4YUXxpe//OWYOnVqTJkyJb7yla/ECSecUHpXDwBwYHvTgfLAAw/Ehz/84dL50qVLIyLivPPOi7Vr18ayZcti586d0dLSEv39/TFz5szYuHFjVFdXl77mu9/9bhx00EFx1llnxc6dO+O0006LtWvXxvjx48vwIwEAY12hWCwWKz3EmzU4OBg1NTUxMDBwwN2PcuwVP6v0CLyF/vbN+ZUeAaBs3syf3z6LBwBIR6AAAOkIFAAgnTd9kywAo8M9ZgcW95i9PldQAIB0BAoAkI5AAQDSESgAQDoCBQBIR6AAAOkIFAAgHYECAKQjUACAdAQKAJCOQAEA0hEoAEA6AgUASEegAADpCBQAIB2BAgCkI1AAgHQECgCQjkABANIRKABAOgIFAEhHoAAA6QgUACAdgQIApCNQAIB0BAoAkI5AAQDSESgAQDoCBQBIR6AAAOkIFAAgHYECAKQjUACAdAQKAJCOQAEA0hEoAEA6AgUASEegAADpCBQAIB2BAgCkI1AAgHQECgCQjkABANIRKABAOgIFAEhHoAAA6QgUACAdgQIApFP2QHnppZfi61//ejQ2NsbEiRPjuOOOi2uuuSb27NlT2lMsFqOtrS3q6+tj4sSJMWfOnNi2bVu5RwEAxqiyB8p1110XP/jBD6KrqyseffTRWLlyZXzrW9+K66+/vrRn5cqVsWrVqujq6ootW7ZEXV1dzJ07N4aGhso9DgAwBpU9UP7whz/EJz7xiZg/f34ce+yx8alPfSqam5vjgQceiIiXr550dnbGihUrYuHChTF9+vRYt25dvPDCC7F+/fpyjwMAjEFlD5RTTz01fv3rX8fjjz8eERF//OMf4957742PfexjERGxffv26O3tjebm5tLXVFVVxezZs2Pz5s3lHgcAGIMOKvcTfu1rX4uBgYF45zvfGePHj4/du3fHtddeG5/97GcjIqK3tzciImpra0d8XW1tbezYseNVn3N4eDiGh4dL54ODg+UeGwBIpOxXUG677ba49dZbY/369fHggw/GunXr4tvf/nasW7duxL5CoTDivFgs7rO2V0dHR9TU1JSOhoaGco8NACRS9kD56le/GldccUV85jOfiRNOOCHOPffcuPzyy6OjoyMiIurq6iLi/19J2auvr2+fqyp7LV++PAYGBkpHT09PuccGABIpe6C88MILMW7cyKcdP3586W3GjY2NUVdXF93d3aXHd+3aFZs2bYpZs2a96nNWVVXF5MmTRxwAwP6r7PegnHnmmXHttdfGtGnT4t3vfnc89NBDsWrVqrjgggsi4uVf7bS2tkZ7e3s0NTVFU1NTtLe3x6RJk2LRokXlHgcAGIPKHijXX399fOMb34iWlpbo6+uL+vr6WLJkSVx55ZWlPcuWLYudO3dGS0tL9Pf3x8yZM2Pjxo1RXV1d7nEAgDGoUCwWi5Ue4s0aHByMmpqaGBgYOOB+3XPsFT+r9Ai8hf72zfmVHoG3kNf3geVAfH2/mT+/fRYPAJCOQAEA0hEoAEA6AgUASEegAADpCBQAIB2BAgCkI1AAgHQECgCQjkABANIRKABAOgIFAEhHoAAA6QgUACAdgQIApCNQAIB0BAoAkI5AAQDSESgAQDoCBQBIR6AAAOkIFAAgHYECAKQjUACAdAQKAJCOQAEA0hEoAEA6AgUASEegAADpCBQAIB2BAgCkI1AAgHQECgCQjkABANIRKABAOgIFAEhHoAAA6QgUACAdgQIApCNQAIB0BAoAkI5AAQDSESgAQDoCBQBIR6AAAOkIFAAgHYECAKQjUACAdAQKAJCOQAEA0hEoAEA6AgUASEegAADpjEqgPPXUU3HOOefE1KlTY9KkSfG+970vtm7dWnq8WCxGW1tb1NfXx8SJE2POnDmxbdu20RgFABiDyh4o/f39ccopp8SECRPiF7/4RTzyyCPxne98Jw477LDSnpUrV8aqVauiq6srtmzZEnV1dTF37twYGhoq9zgAwBh0ULmf8LrrrouGhoa4+eabS2vHHnts6Z+LxWJ0dnbGihUrYuHChRERsW7duqitrY3169fHkiVLyj0SADDGlP0Kyp133hknnXRSfPrTn44jjzwyTjzxxLjhhhtKj2/fvj16e3ujubm5tFZVVRWzZ8+OzZs3v+pzDg8Px+Dg4IgDANh/lT1QnnjiiVi9enU0NTXFL3/5y7jooovisssui1tuuSUiInp7eyMiora2dsTX1dbWlh57pY6OjqipqSkdDQ0N5R4bAEik7IGyZ8+eeP/73x/t7e1x4oknxpIlS+KLX/xirF69esS+QqEw4rxYLO6zttfy5ctjYGCgdPT09JR7bAAgkbIHylFHHRXvete7Rqwdf/zx8eSTT0ZERF1dXUTEPldL+vr69rmqsldVVVVMnjx5xAEA7L/KHiinnHJKPPbYYyPWHn/88TjmmGMiIqKxsTHq6uqiu7u79PiuXbti06ZNMWvWrHKPAwCMQWV/F8/ll18es2bNivb29jjrrLPi/vvvjzVr1sSaNWsi4uVf7bS2tkZ7e3s0NTVFU1NTtLe3x6RJk2LRokXlHgcAGIPKHignn3xy3HHHHbF8+fK45pprorGxMTo7O2Px4sWlPcuWLYudO3dGS0tL9Pf3x8yZM2Pjxo1RXV1d7nEAgDGo7IESEbFgwYJYsGDBaz5eKBSira0t2traRuPbAwBjnM/iAQDSESgAQDoCBQBIR6AAAOkIFAAgHYECAKQjUACAdAQKAJCOQAEA0hEoAEA6AgUASEegAADpCBQAIB2BAgCkI1AAgHQECgCQjkABANIRKABAOgIFAEhHoAAA6QgUACAdgQIApCNQAIB0BAoAkI5AAQDSESgAQDoCBQBIR6AAAOkIFAAgHYECAKQjUACAdAQKAJCOQAEA0hEoAEA6AgUASEegAADpCBQAIB2BAgCkI1AAgHQECgCQjkABANIRKABAOgIFAEhHoAAA6QgUACAdgQIApCNQAIB0BAoAkI5AAQDSESgAQDoCBQBIR6AAAOmMeqB0dHREoVCI1tbW0lqxWIy2traor6+PiRMnxpw5c2Lbtm2jPQoAMEaMaqBs2bIl1qxZE+95z3tGrK9cuTJWrVoVXV1dsWXLlqirq4u5c+fG0NDQaI4DAIwRoxYozz33XCxevDhuuOGGOPzww0vrxWIxOjs7Y8WKFbFw4cKYPn16rFu3Ll544YVYv379aI0DAIwhoxYoF198ccyfPz9OP/30Eevbt2+P3t7eaG5uLq1VVVXF7NmzY/Pmza/6XMPDwzE4ODjiAAD2XweNxpNu2LAhHnzwwdiyZcs+j/X29kZERG1t7Yj12tra2LFjx6s+X0dHR1x99dXlHxQASKnsV1B6enriS1/6Utx6661xyCGHvOa+QqEw4rxYLO6zttfy5ctjYGCgdPT09JR1ZgAgl7JfQdm6dWv09fXFjBkzSmu7d++Oe+65J7q6uuKxxx6LiJevpBx11FGlPX19fftcVdmrqqoqqqqqyj0qAJBU2a+gnHbaafHnP/85Hn744dJx0kknxeLFi+Phhx+O4447Lurq6qK7u7v0Nbt27YpNmzbFrFmzyj0OADAGlf0KSnV1dUyfPn3E2qGHHhpTp04trbe2tkZ7e3s0NTVFU1NTtLe3x6RJk2LRokXlHgcAGING5SbZN7Js2bLYuXNntLS0RH9/f8ycOTM2btwY1dXVlRgHAEjmLQmU3/3udyPOC4VCtLW1RVtb21vx7QGAMcZn8QAA6QgUACAdgQIApCNQAIB0BAoAkI5AAQDSESgAQDoCBQBIR6AAAOkIFAAgHYECAKQjUACAdAQKAJCOQAEA0hEoAEA6AgUASEegAADpCBQAIB2BAgCkI1AAgHQECgCQjkABANIRKABAOgIFAEhHoAAA6QgUACAdgQIApCNQAIB0BAoAkI5AAQDSESgAQDoCBQBIR6AAAOkIFAAgHYECAKQjUACAdAQKAJCOQAEA0hEoAEA6AgUASEegAADpCBQAIB2BAgCkI1AAgHQECgCQjkABANIRKABAOgIFAEhHoAAA6QgUACAdgQIApCNQAIB0BAoAkE7ZA6WjoyNOPvnkqK6ujiOPPDI++clPxmOPPTZiT7FYjLa2tqivr4+JEyfGnDlzYtu2beUeBQAYo8oeKJs2bYqLL7447rvvvuju7o6XXnopmpub4/nnny/tWblyZaxatSq6urpiy5YtUVdXF3Pnzo2hoaFyjwMAjEEHlfsJ77777hHnN998cxx55JGxdevW+NCHPhTFYjE6OztjxYoVsXDhwoiIWLduXdTW1sb69etjyZIl5R4JABhjRv0elIGBgYiImDJlSkREbN++PXp7e6O5ubm0p6qqKmbPnh2bN29+1ecYHh6OwcHBEQcAsP8a1UApFouxdOnSOPXUU2P69OkREdHb2xsREbW1tSP21tbWlh57pY6OjqipqSkdDQ0Nozk2AFBhoxool1xySfzpT3+KH//4x/s8VigURpwXi8V91vZavnx5DAwMlI6enp5RmRcAyKHs96Dsdemll8add94Z99xzTxx99NGl9bq6uoh4+UrKUUcdVVrv6+vb56rKXlVVVVFVVTVaowIAyZT9CkqxWIxLLrkkbr/99vjNb34TjY2NIx5vbGyMurq66O7uLq3t2rUrNm3aFLNmzSr3OADAGFT2KygXX3xxrF+/Pn76059GdXV16b6SmpqamDhxYhQKhWhtbY329vZoamqKpqamaG9vj0mTJsWiRYvKPQ4AMAaVPVBWr14dERFz5swZsX7zzTfH5z//+YiIWLZsWezcuTNaWlqiv78/Zs6cGRs3bozq6upyjwMAjEFlD5RisfiGewqFQrS1tUVbW1u5vz0AsB/wWTwAQDoCBQBIR6AAAOkIFAAgHYECAKQjUACAdAQKAJCOQAEA0hEoAEA6AgUASEegAADpCBQAIB2BAgCkI1AAgHQECgCQjkABANIRKABAOgIFAEhHoAAA6QgUACAdgQIApCNQAIB0BAoAkI5AAQDSESgAQDoCBQBIR6AAAOkIFAAgHYECAKQjUACAdAQKAJCOQAEA0hEoAEA6AgUASEegAADpCBQAIB2BAgCkI1AAgHQECgCQjkABANIRKABAOgIFAEhHoAAA6QgUACAdgQIApCNQAIB0BAoAkI5AAQDSESgAQDoCBQBIR6AAAOkIFAAgnYoGyve///1obGyMQw45JGbMmBG///3vKzkOAJBExQLltttui9bW1lixYkU89NBD8cEPfjDmzZsXTz75ZKVGAgCSqFigrFq1Ki688ML4whe+EMcff3x0dnZGQ0NDrF69ulIjAQBJHFSJb7pr167YunVrXHHFFSPWm5ubY/PmzfvsHx4ejuHh4dL5wMBAREQMDg6O7qAJ7Rl+odIj8BY6EP8dP5B5fR9YDsTX996fuVgsvuHeigTKP/7xj9i9e3fU1taOWK+trY3e3t599nd0dMTVV1+9z3pDQ8OozQgZ1HRWegJgtBzIr++hoaGoqal53T0VCZS9CoXCiPNisbjPWkTE8uXLY+nSpaXzPXv2xL/+9a+YOnXqq+5n/zI4OBgNDQ3R09MTkydPrvQ4QBl5fR9YisViDA0NRX19/RvurUigHHHEETF+/Ph9rpb09fXtc1UlIqKqqiqqqqpGrB122GGjOSIJTZ482X/AYD/l9X3geKMrJ3tV5CbZgw8+OGbMmBHd3d0j1ru7u2PWrFmVGAkASKRiv+JZunRpnHvuuXHSSSfFBz7wgVizZk08+eSTcdFFF1VqJAAgiYoFytlnnx3//Oc/45prrolnnnkmpk+fHj//+c/jmGOOqdRIJFVVVRVXXXXVPr/mA8Y+r29eS6H4n7zXBwDgLeSzeACAdAQKAJCOQAEA0hEoAEA6AgUASEegAJDKU089VekRSKCin8UDr+aCCy74j/bddNNNozwJ8Fbq7e2Na6+9Nn74wx/Gzp07Kz0OFeYKCumsXbs2fvvb38azzz4b/f39r3kAY8+zzz4bixcvjre//e1RX18f3/ve92LPnj1x5ZVXxnHHHRf33Xefv3wQEf5HbSTU0tISGzZsiGnTpsUFF1wQ55xzTkyZMqXSYwFl0NLSEnfddVecffbZcffdd8ejjz4aZ5xxRvz73/+Oq666KmbPnl3pEUlCoJDS8PBw3H777XHTTTfF5s2bY/78+XHhhRdGc3NzFAqFSo8H/JeOOeaYuPHGG+P000+PJ554It7xjnfEZZddFp2dnZUejWQECunt2LEj1q5dG7fccku8+OKL8cgjj8Tb3va2So8F/BcmTJgQO3bsiPr6+oiImDRpUtx///0xffr0Ck9GNu5BIb1CoRCFQiGKxWLs2bOn0uMA/4M9e/bEhAkTSufjx4+PQw89tIITkZUrKKT0f3/Fc++998aCBQvi/PPPj49+9KMxbpyuhrFq3LhxMW/evNKnF991113xkY98ZJ9Iuf322ysxHol4mzHp/N+bZM8///zYsGFDTJ06tdJjAWVw3nnnjTg/55xzKjQJ2bmCQjrjxo2LadOmxYknnvi6N8T6GxbA/ssVFNL53Oc+5506AAc4V1AAgHTcbQgApCNQAIB0BAoAkI5AAQDSESgAQDoCBQBIR6AAAOkIFAAgnf8HaZGFwjI0Xl4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[60].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d329f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0200</th>\n",
       "      <th>0.0371</th>\n",
       "      <th>0.0428</th>\n",
       "      <th>0.0207</th>\n",
       "      <th>0.0954</th>\n",
       "      <th>0.0986</th>\n",
       "      <th>0.1539</th>\n",
       "      <th>0.1601</th>\n",
       "      <th>0.3109</th>\n",
       "      <th>0.2111</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0027</th>\n",
       "      <th>0.0065</th>\n",
       "      <th>0.0159</th>\n",
       "      <th>0.0072</th>\n",
       "      <th>0.0167</th>\n",
       "      <th>0.0180</th>\n",
       "      <th>0.0084</th>\n",
       "      <th>0.0090</th>\n",
       "      <th>0.0032</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.1021</td>\n",
       "      <td>0.0852</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.1747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.0698</td>\n",
       "      <td>0.1615</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.2918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.1665</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.1443</td>\n",
       "      <td>0.2770</td>\n",
       "      <td>0.2555</td>\n",
       "      <td>0.1712</td>\n",
       "      <td>0.0466</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.0645</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.0822</td>\n",
       "      <td>0.1256</td>\n",
       "      <td>0.1323</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>0.2017</td>\n",
       "      <td>0.2122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109  \\\n",
       "192  0.0203  0.0121  0.0380  0.0128  0.0537  0.0874  0.1021  0.0852  0.1136   \n",
       "171  0.0180  0.0444  0.0476  0.0698  0.1615  0.0887  0.0596  0.1071  0.3175   \n",
       "137  0.0731  0.1249  0.1665  0.1496  0.1443  0.2770  0.2555  0.1712  0.0466   \n",
       "102  0.0162  0.0253  0.0262  0.0386  0.0645  0.0472  0.1056  0.1388  0.0598   \n",
       "122  0.0270  0.0163  0.0341  0.0247  0.0822  0.1256  0.1323  0.1584  0.2017   \n",
       "\n",
       "     0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  \\\n",
       "192  0.1747  ...  0.0134  0.0094  0.0047  0.0045  0.0042  0.0028  0.0036   \n",
       "171  0.2918  ...  0.0122  0.0114  0.0098  0.0027  0.0025  0.0026  0.0050   \n",
       "137  0.1114  ...  0.0444  0.0230  0.0290  0.0141  0.0161  0.0177  0.0194   \n",
       "102  0.1334  ...  0.0071  0.0082  0.0232  0.0198  0.0074  0.0035  0.0100   \n",
       "122  0.2122  ...  0.0189  0.0204  0.0085  0.0043  0.0092  0.0138  0.0094   \n",
       "\n",
       "     0.0090  0.0032  R  \n",
       "192  0.0013  0.0016  M  \n",
       "171  0.0073  0.0022  M  \n",
       "137  0.0207  0.0057  M  \n",
       "102  0.0048  0.0019  M  \n",
       "122  0.0105  0.0093  M  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c075f5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207, 61)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c476659a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0200    0\n",
       "0.0371    0\n",
       "0.0428    0\n",
       "0.0207    0\n",
       "0.0954    0\n",
       "         ..\n",
       "0.0180    0\n",
       "0.0084    0\n",
       "0.0090    0\n",
       "0.0032    0\n",
       "R         0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d52de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop(60,axis='columns')\n",
    "y=data[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e473b18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     R\n",
       "172  0\n",
       "44   1\n",
       "94   1\n",
       "164  0\n",
       "128  0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=pd.get_dummies(y,drop_first=True)\n",
    "y.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7c43893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3f3bcab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((156, 60), (156, 1))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape ,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7042434a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 22:50:46.509456: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-10 22:50:46.915697: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-05-10 22:50:47.906298: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/amal/anaconda3/lib/:/lib:/home/amal/anaconda3/lib/:/lib:/home/amal/anaconda3/lib/:/lib\n",
      "2023-05-10 22:50:47.906384: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/amal/anaconda3/lib/:/lib:/home/amal/anaconda3/lib/:/lib:/home/amal/anaconda3/lib/:/lib\n",
      "2023-05-10 22:50:47.906391: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee57e0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 22:56:34.923179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-10 22:56:35.026059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-10 22:56:35.026323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-10 22:56:35.027003: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-10 22:56:35.028378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-10 22:56:35.028604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-10 22:56:35.028742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-10 22:56:35.744059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-10 22:56:35.744719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-10 22:56:35.744901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-10 22:56:35.745016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1657 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model=keras.Sequential([\n",
    "    keras.layers.Dense(60,input_dim=60,activation='relu'),\n",
    "    keras.layers.Dense(30,activation='relu'),\n",
    "    keras.layers.Dense(15,activation='relu'),\n",
    "    keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06dc131e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 3ms/step - loss: 0.6808 - accuracy: 0.5705\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6473 - accuracy: 0.6603\n",
      "Epoch 3/100\n",
      " 1/20 [>.............................] - ETA: 0s - loss: 0.5471 - accuracy: 0.8750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 22:57:33.452606: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.7372\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5715 - accuracy: 0.7821\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.7949\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7756\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7756\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.8013\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7885\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.8269\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8077\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8077\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3417 - accuracy: 0.8718\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8590\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3338 - accuracy: 0.8397\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3503 - accuracy: 0.8526\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3329 - accuracy: 0.8526\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3083 - accuracy: 0.8590\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2837 - accuracy: 0.8782\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2481 - accuracy: 0.8910\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2789 - accuracy: 0.8654\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3065 - accuracy: 0.8397\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2376 - accuracy: 0.8974\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2353 - accuracy: 0.8974\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2134 - accuracy: 0.9231\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2357 - accuracy: 0.8782\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 0.9167\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2231 - accuracy: 0.9103\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1711 - accuracy: 0.9359\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1629 - accuracy: 0.9359\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1660 - accuracy: 0.9423\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1494 - accuracy: 0.9679\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1593 - accuracy: 0.9359\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1294 - accuracy: 0.9808\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1188 - accuracy: 0.9679\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1201 - accuracy: 0.9615\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1079 - accuracy: 0.9744\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1020 - accuracy: 0.9679\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1298 - accuracy: 0.9551\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0921 - accuracy: 0.9808\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0845 - accuracy: 0.9872\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.9808\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0765 - accuracy: 0.9936\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.9872\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0756 - accuracy: 0.9872\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9872\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9936\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.9808\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0896 - accuracy: 0.9808\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.9744\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9936\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 0.9872\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0327 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0322 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9872\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9872\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9808\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.9744\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9936\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.9936\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.9936\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9808\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 0.9872\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 0.9936\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f78b15b3250>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=100,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "764c9e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8146 - accuracy: 0.8846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.814554750919342, 0.8846153616905212]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d4de414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "   R\n",
      "0  1\n",
      "1  1\n",
      "2  1\n",
      "3  1\n",
      "4  1\n",
      "5  1\n",
      "6  1\n",
      "7  1\n",
      "8  1\n",
      "9  1\n",
      "[1. 0. 1. 1. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(x_test).reshape(-1)\n",
    "print(y[:10])\n",
    "\n",
    "y_pred=np.round(y_pred)\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b05584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new=keras.Sequential([\n",
    "    keras.layers.Dense(60,input_dim=60,activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(30,activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(15,activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "77c79cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90e118a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 4ms/step - loss: 0.7215 - accuracy: 0.4359\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.5513\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5705\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6760 - accuracy: 0.5256\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6607 - accuracy: 0.5705\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.5128\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6821 - accuracy: 0.5385\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.5897\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6594 - accuracy: 0.6346\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6631 - accuracy: 0.6154\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 0.5897\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6500 - accuracy: 0.6538\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6283 - accuracy: 0.6346\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.6090\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6128 - accuracy: 0.6538\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.6859\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6036 - accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6004 - accuracy: 0.6731\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5901 - accuracy: 0.6795\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5994 - accuracy: 0.6859\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7308\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7244\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.7308\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7756\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7692\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.7372\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.7500\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7885\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.8013\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7692\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7885\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.8205\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8269\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.8077\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.8269\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3952 - accuracy: 0.8462\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8077\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.8269\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3684 - accuracy: 0.8782\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8269\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3340 - accuracy: 0.8718\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3377 - accuracy: 0.8526\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3406 - accuracy: 0.8333\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3391 - accuracy: 0.8782\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2746 - accuracy: 0.8526\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3799 - accuracy: 0.8269\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3056 - accuracy: 0.8590\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3920 - accuracy: 0.8077\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2950 - accuracy: 0.8718\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2965 - accuracy: 0.8590\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2968 - accuracy: 0.8846\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2736 - accuracy: 0.8846\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3269 - accuracy: 0.8526\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3186 - accuracy: 0.8654\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2839 - accuracy: 0.8590\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2851 - accuracy: 0.8718\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2777 - accuracy: 0.8590\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2660 - accuracy: 0.8718\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2810 - accuracy: 0.8654\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2215 - accuracy: 0.9359\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2399 - accuracy: 0.9231\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2893 - accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2924 - accuracy: 0.8910\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2863 - accuracy: 0.8910\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2227 - accuracy: 0.9231\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2522 - accuracy: 0.8974\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2299 - accuracy: 0.8974\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2181 - accuracy: 0.8974\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2473 - accuracy: 0.8910\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2818 - accuracy: 0.8718\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2221 - accuracy: 0.9167\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2697 - accuracy: 0.8846\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2013 - accuracy: 0.9231\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1842 - accuracy: 0.9487\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.9359\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1795 - accuracy: 0.9231\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1920 - accuracy: 0.9103\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1827 - accuracy: 0.9487\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1626 - accuracy: 0.9487\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9359\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1984 - accuracy: 0.9231\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1850 - accuracy: 0.9295\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2092 - accuracy: 0.9167\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2143 - accuracy: 0.9167\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1576 - accuracy: 0.9359\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1869 - accuracy: 0.9231\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2145 - accuracy: 0.8974\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1447 - accuracy: 0.9551\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1078 - accuracy: 0.9679\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1563 - accuracy: 0.9487\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1354 - accuracy: 0.9679\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1712 - accuracy: 0.9295\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1374 - accuracy: 0.9551\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1421 - accuracy: 0.9487\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1928 - accuracy: 0.9295\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1745 - accuracy: 0.9359\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9167\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9551\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1307 - accuracy: 0.9551\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1002 - accuracy: 0.9679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f788c695270>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new.fit(x_train,y_train,epochs=100,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "98ac0f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8543 - accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8542724251747131, 0.75]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5338bd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89        26\n",
      "           1       0.95      0.81      0.88        26\n",
      "\n",
      "    accuracy                           0.88        52\n",
      "   macro avg       0.89      0.88      0.88        52\n",
      "weighted avg       0.89      0.88      0.88        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b0c01c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "   R\n",
      "0  1\n",
      "1  1\n",
      "2  1\n",
      "3  1\n",
      "4  1\n",
      "5  1\n",
      "6  1\n",
      "7  1\n",
      "8  1\n",
      "9  1\n",
      "[1. 0. 1. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "y__pred=model_new.predict(x_test).reshape(-1)\n",
    "print(y[:10])\n",
    "\n",
    "y__pred=np.round(y__pred)\n",
    "print(y__pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3bea845f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.88      0.78        26\n",
      "           1       0.84      0.62      0.71        26\n",
      "\n",
      "    accuracy                           0.75        52\n",
      "   macro avg       0.77      0.75      0.75        52\n",
      "weighted avg       0.77      0.75      0.75        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y__pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
